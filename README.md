# Feature-selection-Feature-Engineering

* Feature Selection is one of the core concepts in machine learning which hugely impacts the performance of your model.Feature Selection is the process where you automatically or manually select those features which contribute most to your prediction variable or output in which you are interested in.Having irrelevant features in your data can decrease the accuracy of the models and make your model learn based on irrelevant features.

### Benefits of performing feature selection before modeling your data :
· Reduces Overfitting: Less redundant data means less opportunity to make decisions based on noise.
· Improves Accuracy: Less misleading data means modeling accuracy improves.
· Reduces Training Time: fewer data points reduce algorithm complexity and algorithms train faster.

### Feature Selection Methods :
- Dropping Constant Features 
- Correlation With Heatmap
- Information gain-Mutual Information in Classification
- Information gain-Mutual Information in Regression
- Feature Importance
- Univariate Selection

